---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

**Mengchao Guoï¼ˆéƒ­å­Ÿè¶…ï¼‰** is a researcher focused on multimodal embodied intelligence, knowledge-graph-assisted manipulation, and cognitively inspired humanâ€“machine interaction. His work spans VLA models, spatial knowledge graphs, robotic manipulation, sequential health knowledge graphs, and multimodal physiological-signal fusion. He aims to build generalizable, explainable, and knowledge-augmented intelligent systems capable of long-horizon reasoning and real-world task execution.

He is currently conducting research on *KG-assisted precise robotic manipulation* based on VLA-Adapter + LIBERO-Spatial, focusing on adaptive KG modulation, spatial reasoning, and fine-grained grasping decision systems. His broader research includes *Dual-Stream Transformer for cross-modal physiological signal fusion* and *patient-specific temporal knowledge graphs (PT-TKG)* for personalized healthcare analytics.

Before this, he worked on multimodal sensing systems, clinical knowledge graph construction, and embodied planning frameworks for long-horizon tasks. He has published papers in AI, medical informatics, and robotics, and actively contributes to open-source embodied intelligence toolchains.

ğŸ“£ *Collaborations welcome!*  
I am open to collaborations in embodied AI, multimodal modeling, medical knowledge graphs, and robot manipulation. Please contact me via email.

---

# ğŸ”¥ News
- *2025.12*: &nbsp; Released our **KG-assisted precise grasping** framework with adaptive KG modulation for LIBERO-Spatial.
- *2025.12*: &nbsp; Completed integration of CPE/OE/PC/AC grasping evaluation metrics.
- *2025.11*: &nbsp; Our Dual-Stream Transformer framework for cross-modal physiological signal fusion achieves SOTA on BCI benchmarks.
- *2025.10*: &nbsp; PT-TKG construction pipeline released for personalized temporal medical graphs.

*(è¯·æŒ‰ä½ çš„å®é™…æƒ…å†µå¢å‡æˆ–è°ƒæ•´æ—¶é—´çº¿å†…å®¹)*

---

# ğŸ“ Publications  
*(ä»¥ä¸‹å†…å®¹ä¸ºç»“æ„æ¨¡æ¿ï¼Œè¯·æ›¿æ¢æˆä½ è‡ªå·±çš„è®ºæ–‡åˆ—è¡¨)*

**Year 2025**
- ***KG-Assisted Precise Manipulation via Adaptive Spatial Knowledge Modulation***, Author1, Author2, **Mengchao Guo**, ... Conference/Journal, 2025.
- ***Dual-Stream Transformer for Robust Cross-Modal Physiological Fusion***, Author1, **Mengchao Guo**, ... Conference/Journal, 2025.

**Year 2024**
- ***Patient-specific Temporal Knowledge Graph for Longitudinal Health Prediction***, Author1, **Mengchao Guo**, ... 2024.

**Year 2023**
- ***Multimodal Clinical Representation Learning with Knowledge Constraints***, Author1, Author2, **Mengchao Guo**, ... 2023.

Full list available at **[My Google Scholar](#)**  
ï¼ˆè‹¥ä½ å·²æœ‰ Google Scholar é“¾æ¥ï¼Œç›´æ¥æ›¿æ¢å³å¯ï¼‰

---

# ğŸ‘ª Group / Collaborators  

*(å¦‚æ— è¯¾é¢˜ç»„ï¼Œå¯ä¿ç•™ä¸ºåˆä½œä¼™ä¼´åˆ—è¡¨)*

- ***Collaborators:***  
  - Prof. A  
  - Dr. B  
  - Dr. C  

- ***Project Team Members:***  
  - Student 1, Student 2, Student 3  
  - Research Assistants: A, B  

---

# ğŸ’ğŸ» Academic Service  
*(æ ¹æ®çœŸå®æƒ…å†µå¡«å†™)*

- Reviewer of: NeurIPS, ICLR, AAAI, IJCAI, TNNLS, JBHI, etc.  
- Program Committee Member: XXX 2025  
- Organizer: Workshop on Embodied AI & Knowledge Graphs 2025  

---

# ğŸ… Awards  
*(ç¤ºä¾‹ï¼Œå¯è‡ªè¡Œä¿®æ”¹)*

- Best Paper Award, XXXX 2025  
- Outstanding Student Research Award, 2024  
- National Scholarship, 2023  

---

# ğŸ‘©ğŸ»â€ğŸ« Teaching / Mentoring  
*(å¦‚æ— å¯åˆ é™¤)*

- 2025 Fall: Introduction to Embodied Intelligence  
- 2024 Spring: Multimodal AI Systems  

---

# ğŸ« Educations  
*(æ ¹æ®ä½ çš„æƒ…å†µä¿®æ”¹)*

- *20xx â€“ 20xx*, Ph.D., Field, University  
- *20xx â€“ 20xx*, Master, Field, University  
- *20xx â€“ 20xx*, Bachelor, Field, University  

---

# ğŸ’» Research Experiences  
*(æ ¹æ®ä½ çš„æƒ…å†µä¿®æ”¹)*

- *2024 â€“ now*, Researcher, Multimodal Embodied Intelligence  
- *2023 â€“ 2024*, Research Assistant, Medical AI & Knowledge Graphs  
- *2021 â€“ 2023*, Developer, Sensor-based Multimodal Systems

---
